{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f675f31",
   "metadata": {},
   "source": [
    "### Load a math dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "\n",
    "import datasets\n",
    "import contextlib\n",
    "import rigging as rg\n",
    "\n",
    "def is_basic_question(sample: dict[str, t.Any]) -> bool:\n",
    "    with contextlib.suppress(ValueError):\n",
    "        float(sample[\"answer\"])\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "dataset = [\n",
    "    rg.Message(\"user\", sample[\"problem\"], metadata={**sample})\n",
    "    for sample in datasets.load_dataset(\"HuggingFaceH4/MATH-500\", split=\"test\").filter(is_basic_question)\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(dataset)} basic questions from MATH-500.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe0a3f",
   "metadata": {},
   "source": [
    "### Define tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rigging as rg\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Dedicated calculator tool\n",
    "\n",
    "class Calculator:\n",
    "    @rg.tool_method(catch=True)\n",
    "    def add(self, x: float, y: float) -> float:\n",
    "        \"\"\"Adds two numbers.\"\"\"\n",
    "        return x + y\n",
    "\n",
    "    @rg.tool_method(catch=True)\n",
    "    def subtract(self, x: float, y: float) -> float:\n",
    "        \"\"\"Subtracts the second number from the first.\"\"\"\n",
    "        return x - y\n",
    "\n",
    "    @rg.tool_method(catch=True)\n",
    "    def multiply(self, x: float, y: float) -> float:\n",
    "        \"\"\"Multiplies two numbers.\"\"\"\n",
    "        return x * y\n",
    "\n",
    "    @rg.tool_method(catch=True)\n",
    "    def divide(self, x: float, y: float) -> float:\n",
    "        \"\"\"Divides the first number by the second.\"\"\"\n",
    "        if y == 0:\n",
    "            raise ValueError(\"Cannot divide by zero.\")\n",
    "        return x / y\n",
    "\n",
    "calculator = Calculator()\n",
    "\n",
    "# Python execution tool\n",
    "\n",
    "@rg.tool(catch=True)\n",
    "def execute_python(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes Python code and returns stdout from the execution.\n",
    "    \n",
    "    - Use print() to output results.\n",
    "    - Be thoughtful with indentation and syntax.\n",
    "    \"\"\"\n",
    "    output = StringIO()\n",
    "    with redirect_stdout(output):\n",
    "        exec(code)\n",
    "    return output.getvalue()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea856c",
   "metadata": {},
   "source": [
    "### Define our agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "# Define a model for parsing the agent answer\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    value: str\n",
    "\n",
    "# Callback to inspect results after the agent execution\n",
    "\n",
    "async def inspect_results(chat: rg.Chat) -> rg.Chat:\n",
    "    used_tools = any(msg.tool_calls for msg in chat.messages if msg.role == \"assistant\")\n",
    "    answer = chat.message_metadata[\"answer\"]\n",
    "    agent_answer = chat.last.try_parse(Answer)\n",
    "\n",
    "    correct = False\n",
    "    with contextlib.suppress(ValueError):\n",
    "        correct = agent_answer is not None and float(agent_answer.value) == float(answer)\n",
    "    \n",
    "    return chat.meta(\n",
    "        correct=correct,\n",
    "        gave_answer=answer is not None,\n",
    "        agent_answer=agent_answer.value if agent_answer else None,\n",
    "        used_tools=used_tools,\n",
    "        true_answer=answer\n",
    "    )\n",
    "\n",
    "\n",
    "# Build our core pipeline\n",
    "\n",
    "pipeline = (\n",
    "    rg.get_generator(\"groq/meta-llama/llama-4-maverick-17b-128e-instruct\")\n",
    "    .chat(\"Answer math questions and return basic floats between <answer></answer> tags.\")\n",
    "    .until_parsed_as(Answer)\n",
    "    .then(inspect_results)\n",
    "    .catch(Exception, on_failed=\"include\")\n",
    ")\n",
    "\n",
    "# Define 3 agents with different capabilities\n",
    "\n",
    "agent_no_tools = pipeline.clone().meta(variant=\"no_tools\")\n",
    "agent_with_calculator = pipeline.clone().using(calculator, mode=\"xml\").meta(variant=\"with_calculator\")\n",
    "agent_with_python = pipeline.clone().using(execute_python, mode=\"xml\").meta(variant=\"with_python\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dae7e4",
   "metadata": {},
   "source": [
    "### Run 10 samples through our 3 agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "samples = random.sample(dataset, 10)\n",
    "\n",
    "chats_no_tools = await agent_no_tools.run_batch(samples)\n",
    "chats_with_calculator = await agent_with_calculator.run_batch(samples)\n",
    "chats_with_python = await agent_with_python.run_batch(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8305557",
   "metadata": {},
   "source": [
    "### Calculate success rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436079a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_success_rate(chats: t.List[rg.Chat]) -> float:\n",
    "    return sum(chat.metadata.get(\"correct\", False) for chat in chats) / len(chats)\n",
    "\n",
    "no_tools_success_rate = get_success_rate(chats_no_tools)\n",
    "with_calculator_success_rate = get_success_rate(chats_with_calculator)\n",
    "with_python_success_rate = get_success_rate(chats_with_python)\n",
    "\n",
    "print(f\"Success rate without tools:       {no_tools_success_rate:.2%}\")\n",
    "print(f\"Success rate with calculator:     {with_calculator_success_rate:.2%}\")\n",
    "print(f\"Success rate with Python:         {with_python_success_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12655a0c",
   "metadata": {},
   "source": [
    "### Tokenize the chat with a tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ef6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = await chats_with_python.to_tokens('Qwen/Qwen2.5-1.5B-Instruct', transform=\"json-with-tag\")\n",
    "\n",
    "print(tokenized[0].metadata)\n",
    "print(tokenized[0].slices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
