---
title: rigging.tokenizer
---

{/*
::: rigging.tokenizer
*/}

get\_tokenizer
--------------

```python
get_tokenizer(
    tokenizer_id: str, **tokenizer_kwargs: Any
) -> t.Any
```

Get the tokenizer from transformers model identifier, or from an already loaded tokenizer.

**Parameters:**

* **`tokenizer_id`**
  (`str`)
  –The model identifier (string) or an already loaded tokenizer.
* **`tokenizer_kwargs`**
  (`Any`, default:
  `{}`
  )
  –Additional keyword arguments for the tokenizer initialization.

**Returns:**

* `Any`
  –An instance of `AutoTokenizer`.

<Accordion title="Source code in rigging/tokenize/tokenizer.py" icon="code">
```python
def get_tokenizer(
    tokenizer_id: str,
    **tokenizer_kwargs: t.Any,
) -> t.Any:
    """
    Get the tokenizer from transformers model identifier, or from an already loaded tokenizer.

    Args:
        tokenizer_id: The model identifier (string) or an already loaded tokenizer.
        tokenizer_kwargs: Additional keyword arguments for the tokenizer initialization.

    Returns:
        An instance of `AutoTokenizer`.
    """
    try:
        from transformers import AutoTokenizer

        tokenizer = AutoTokenizer.from_pretrained(
            tokenizer_id,
            **tokenizer_kwargs,
        )
        logger.success(f"Loaded tokenizer for model '{tokenizer_id}'")

    except Exception as e:
        # Catch all exceptions to handle any issues with loading the tokenizer
        raise RuntimeError(
            f"Failed to load tokenizer for model '{tokenizer_id}': {e}",
        ) from e

    return tokenizer
```


</Accordion>